{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"0QAkxLpaGhGT","outputId":"ae30ad64-e91f-483f-e1b0-3c64de03c9ff","executionInfo":{"status":"error","timestamp":1748348500171,"user_tz":-330,"elapsed":19505,"user":{"displayName":"Lahari Sadhana","userId":"16351189879560630071"}}},"outputs":[{"output_type":"error","ename":"MessageError","evalue":"Error: credential propagation was unsuccessful","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-fecf1f920688>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/full_df.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}],"source":["import os\n","import seaborn as sns\n","import pandas as pd\n","import numpy as np\n","import cv2 as cv\n","from tqdm import tqdm\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.applications.vgg16 import VGG16\n","from tensorflow.keras import layers\n","from tensorflow.keras import Sequential\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import precision_score\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import load_img,img_to_array\n","from tensorflow.keras.layers import Flatten,Dense,Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.utils import to_categorical\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","dataset = pd.read_csv(\"/content/full_df.csv\")\n","\n","dataset\n","\n","def process_dataset(data):\n","\n","    data[\"left_cataract\"] = data[\"Left-Diagnostic Keywords\"].apply(lambda x: has_condn(\"cataract\",x))\n","    data[\"right_cataract\"] = data[\"Right-Diagnostic Keywords\"].apply(lambda x: has_condn(\"cataract\",x))\n","\n","    data[\"LD\"] = data[\"Left-Diagnostic Keywords\"].apply(lambda x: has_condn(\"non proliferative retinopathy\",x))\n","    data[\"RD\"] = data[\"Right-Diagnostic Keywords\"].apply(lambda x: has_condn(\"non proliferative retinopathy\",x))\n","\n","    data[\"LG\"] = data[\"Left-Diagnostic Keywords\"].apply(lambda x: has_condn(\"glaucoma\",x))\n","    data[\"RG\"] = data[\"Right-Diagnostic Keywords\"].apply(lambda x: has_condn(\"glaucoma\",x))\n","\n","    data[\"LH\"] = data[\"Left-Diagnostic Keywords\"].apply(lambda x: has_condn(\"hypertensive\",x))\n","    data[\"RH\"] = data[\"Right-Diagnostic Keywords\"].apply(lambda x: has_condn(\"hypertensive\",x))\n","\n","    data[\"LM\"] = data[\"Left-Diagnostic Keywords\"].apply(lambda x: has_condn(\"myopia\",x))\n","    data[\"RM\"] = data[\"Right-Diagnostic Keywords\"].apply(lambda x: has_condn(\"myopia\",x))\n","\n","    data[\"LA\"] = data[\"Left-Diagnostic Keywords\"].apply(lambda x: has_condn(\"macular degeneration\",x))\n","    data[\"RA\"] = data[\"Right-Diagnostic Keywords\"].apply(lambda x: has_condn(\"macular degeneration\",x))\n","\n","    data[\"LO\"] = data[\"Left-Diagnostic Keywords\"].apply(lambda x: has_condn(\"drusen\",x))\n","    data[\"RO\"] = data[\"Right-Diagnostic Keywords\"].apply(lambda x: has_condn(\"drusen\",x))\n","\n","    left_cataract_images = data.loc[(data.C ==1) & (data.left_cataract == 1)][\"Left-Fundus\"].values\n","    right_cataract_images = data.loc[(data.C == 1) & (data.right_cataract == 1)][\"Right-Fundus\"].values\n","\n","    left_normal = data.loc[(data.C == 0) & (data[\"Left-Diagnostic Keywords\"] == \"normal fundus\")]['Left-Fundus'].sample(350,random_state=42).values\n","    right_normal = data.loc[(data.C == 0) & (data[\"Right-Diagnostic Keywords\"] == \"normal fundus\")]['Right-Fundus'].sample(350,random_state=42).values\n","\n","    left_diab = data.loc[(data.C == 0) & (data.LD == 1)][\"Left-Fundus\"].values\n","    right_diab = data.loc[(data.C == 0) & (data.RD == 1)][\"Right-Fundus\"].values\n","\n","    left_glaucoma = data.loc[(data.C == 0) & (data.LG == 1)][\"Left-Fundus\"].values\n","    right_glaucoma = data.loc[(data.C == 0) & (data.RG == 1)][\"Right-Fundus\"].values\n","\n","    left_hyper = data.loc[(data.C == 0) & (data.LH == 1)][\"Left-Fundus\"].values\n","    right_hyper = data.loc[(data.C == 0) & (data.RH == 1)][\"Right-Fundus\"].values\n","\n","    left_myopia = data.loc[(data.C == 0) & (data.LM == 1)][\"Left-Fundus\"].values\n","    right_myopia = data.loc[(data.C == 0) & (data.RM == 1)][\"Right-Fundus\"].values\n","\n","    left_age = data.loc[(data.C == 0) & (data.LA == 1)][\"Left-Fundus\"].values\n","    right_age = data.loc[(data.C == 0) & (data.RA == 1)][\"Right-Fundus\"].values\n","\n","    left_other = data.loc[(data.C == 0) & (data.LO == 1)][\"Left-Fundus\"].values\n","    right_other = data.loc[(data.C == 0) & (data.RO == 1)][\"Right-Fundus\"].values\n","\n","    normalones = np.concatenate((left_normal,right_normal),axis = 0);\n","    cataractones = np.concatenate((left_cataract_images,right_cataract_images),axis = 0);\n","    diabones = np.concatenate((left_diab,right_diab),axis = 0);\n","    glaucoma = np.concatenate((left_glaucoma,right_glaucoma),axis = 0);\n","    hyper = np.concatenate((left_hyper,right_hyper),axis = 0);\n","    myopia = np.concatenate((left_myopia,right_myopia),axis = 0);\n","    age = np.concatenate((left_age,right_age),axis=0);\n","    other = np.concatenate((left_other,right_other),axis = 0);\n","\n","    return normalones,cataractones,diabones,glaucoma,hyper,myopia,age,other;\n","\n","def has_condn(term, text):\n","    if term in text:\n","        return 1\n","    else:\n","        return 0\n","\n","normal , cataract , diab, glaucoma , hyper , myopia , age, other = process_dataset(dataset);\n","\n","print(\"Dataset stats::\")\n","print(\"Normal ::\" , len(normal))\n","print(\"Cataract ::\" , len(cataract))\n","print(\"Diabetes ::\" , len(diab))\n","print(\"Glaucoma ::\" , len(glaucoma))\n","print(\"Hypertension ::\" , len(hyper))\n","print(\"Myopia ::\" , len(myopia))\n","print(\"Age Issues ::\" , len(age))\n","print(\"Other ::\" , len(other))\n","\n","from sklearn.preprocessing import LabelEncoder\n","\n","label_encoders = {}\n","for column in dataset.select_dtypes(include=['object']).columns:\n","    le = LabelEncoder()\n","    dataset[column] = le.fit_transform(dataset[column])\n","    label_encoders[column] = le\n","\n","print(dataset.corr())\n","\n","plt.figure(figsize = (15,8))\n","sns.heatmap(dataset.corr(), annot=True, linewidth=2, linecolor = 'lightgray')\n","plt.show()\n","\n","from tensorflow.keras.preprocessing.image import load_img,img_to_array\n","from tqdm import tqdm\n","import cv2\n","import random\n","\n","dataset_dir = \"/content/gdrive/MyDrive/preprocessed_images/\"\n","image_size=224\n","labels = []\n","dataset = []\n","def data_gen(imagecategory , label):\n","    for img in tqdm(imagecategory):\n","        imgpath = os.path.join(dataset_dir,img);\n","\n","        try:\n","            image = cv2.imread(imgpath,cv2.IMREAD_COLOR)\n","            image = cv2.resize(image,(image_size,image_size))\n","        except:\n","            continue;\n","        dataset.append([np.array(image),np.array(label)]);\n","    random.shuffle(dataset);\n","\n","    return dataset;\n","\n","dataset = data_gen(normal,0)\n","dataset = data_gen(cataract,1)\n","dataset = data_gen(diab,2)\n","dataset = data_gen(glaucoma,3)\n","dataset = data_gen(hyper,4)\n","dataset = data_gen(myopia,5)\n","dataset = data_gen(age,6)\n","dataset = data_gen(other,7)\n","\n","len(dataset)\n","\n","plt.figure(figsize=(12,7))\n","for i in range(10):\n","    sample = random.choice(range(len(dataset)))\n","    image = dataset[sample][0]\n","    category = dataset[sample][1]\n","\n","    if category== 0:\n","        label = \"Normal\"\n","    elif category == 1 :\n","        label = \"Cataract\"\n","    elif category == 2:\n","        label = \"Diabetes\"\n","    elif category == 3:\n","        label = \"Glaucoma\"\n","    elif category == 4:\n","        label = \"Hypertension\"\n","    elif category == 5:\n","        label = \"Myopia\"\n","    elif category == 6:\n","        label = \"Age Issues\"\n","    else:\n","        label = \"Other\"\n","\n","    plt.subplot(2,6,i+1)\n","    plt.imshow(image)\n","    plt.xlabel(label)\n","plt.tight_layout()\n","\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","\n","train_x = np.array([i[0] for i in dataset]).reshape(-1,image_size,image_size,3);\n","train_y = np.array([i[1] for i in dataset])\n","\n","x_train, x_temp, y_train, y_temp = train_test_split(train_x, train_y, test_size=0.2, random_state=42)\n","x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)\n","\n","\n","y_train_cat = to_categorical(y_train, num_classes=8)\n","y_val_cat = to_categorical(y_val, num_classes=8)\n","y_test_cat = to_categorical(y_test, num_classes=8)\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","idg = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","\n","    horizontal_flip=True,\n","    vertical_flip=False,\n","    fill_mode='nearest'\n",")\n","\n","idg_test = ImageDataGenerator(rescale=1./255)\n","\n","idg.fit(x_train)\n","idg.fit(x_val)\n","idg_test.fit(x_test)\n","\n","import tensorflow as tf\n","from tensorflow.keras.applications.vgg16 import VGG16\n","\n","input_shape = (224, 224, 3)\n","vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n","\n","vgg16.summary()\n","\n","for layer in vgg16.layers:\n","    layer.trainable = False\n","\n","input_shape = (224, 224, 3)\n","vgg16 = keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n","\n","flat = layers.Flatten()(vgg16.output)\n","dense1 = layers.Dense(2048, activation=\"relu\")(flat)\n","dropout1 = layers.Dropout(0.4)(dense1)\n","dense2 = layers.Dense(2048, activation=\"relu\")(dropout1)\n","dropout2 = layers.Dropout(0.4)(dense2)\n","output = layers.Dense(8, activation=\"softmax\")(dropout2)\n","\n","final_vgg16 = tf.keras.models.Model(inputs=[vgg16.input], outputs=[output])\n","\n","final_vgg16.summary()\n","\n","count = 0\n","for layer in final_vgg16.layers:\n","  count = count +1\n","print(count)\n","\n","tf.keras.utils.plot_model(final_vgg16, show_shapes = True, show_layer_names=True)\n","\n","from tensorflow.keras.optimizers import Adam\n","final_vgg16.compile(optimizer=Adam(learning_rate=1e-4),\n","                    loss='categorical_crossentropy',\n","                    metrics=['accuracy'])\n","\n","train_data = (x_train, y_train_cat)\n","validation_data = (x_val, y_val_cat)\n","test_data = (x_test, y_test_cat)\n","\n","history = final_vgg16.fit(train_data[0], train_data[1], validation_data=(validation_data[0], validation_data[1]), batch_size=32, epochs=50)\n","\n","train_loss, train_accuracy = final_vgg16.evaluate(train_data[0], train_data[1], verbose=0)\n","print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n","\n","val_loss, val_accuracy = final_vgg16.evaluate(validation_data[0], validation_data[1], verbose=0)\n","print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n","\n","test_loss, test_accuracy = final_vgg16.evaluate(test_data[0], test_data[1], verbose=0)\n","print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n","\n","from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n","y_pred = []\n","for i in final_vgg16.predict(x_test):\n","    y_pred.append(np.argmax(np.array(i)).astype(\"int32\"))\n","\n","print(y_pred)\n","\n","plt.figure(figsize=(12,7))\n","for i in range(20):\n","    sample = random.choice(range(len(x_test)))\n","    image = x_test[sample]\n","    category = y_test[sample]\n","    pred_category = y_pred[sample]\n","\n","    if category== 0:\n","        label = \"Normal\"\n","    elif category == 1 :\n","        label = \"Cataract\"\n","    elif category == 2:\n","        label = \"Diabetes\"\n","    elif category == 3:\n","        label = \"Glaucoma\"\n","    elif category == 4:\n","        label = \"Hypertension\"\n","    elif category == 5:\n","        label = \"Myopia\"\n","    elif category == 6:\n","        label = \"Age Issues\"\n","    else:\n","        label = \"Other\"\n","\n","    if pred_category== 0:\n","        pred_label = \"Normal\"\n","    elif pred_category == 1 :\n","        pred_label = \"Cataract\"\n","    elif pred_category == 2:\n","        pred_label = \"Diabetes\"\n","    elif pred_category == 3:\n","        pred_label = \"Glaucoma\"\n","    elif pred_category == 4:\n","        pred_label = \"Hypertension\"\n","    elif pred_category == 5:\n","        pred_label = \"Myopia\"\n","    elif pred_category == 6:\n","        pred_label = \"Age Issues\"\n","    else:\n","        pred_label = \"Other\"\n","\n","    plt.subplot(4,5,i+1)\n","    plt.imshow(image)\n","    plt.xlabel(\"Actual:{}\\nPrediction:{}\".format(label,pred_label))\n","plt.tight_layout()\n","\n","final_vgg16.save(\"ODIR_VGG16.h5\")\n","\n","final_vgg16.save('ODIR_VGG16.keras')\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Validation'], loc='upper left')\n","plt.show()\n","\n","\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Model accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Validation'], loc='upper left')\n","plt.show()\n","\n","from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n","\n","class_names = ['Normal', 'Cataract', 'Diabetes', 'Glaucoma', 'Hypertension', 'Myopia', 'Age Issues', 'Other']\n","y_pred = final_vgg16.predict(x_test)\n","\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","\n","y_true_classes = np.argmax(y_test_cat, axis=1)\n","\n","report = classification_report(y_true_classes, y_pred_classes)\n","print(report)\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix, classification_report\n","from tensorflow.keras.models import load_model\n","\n","class_names = [\n","    \"Normal\", \"Cataract\", \"Diabetes\", \"Glaucoma\",\n","    \"Hypertension\", \"Myopia\", \"Age Issues\", \"Other\"\n","]\n","\n","y_true = np.argmax(y_test_cat, axis=1)\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","\n","conf_matrix = confusion_matrix(y_true, y_pred_classes)\n","\n","# Display the confusion matrix\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n","plt.xlabel(\"Predicted Labels\")\n","plt.ylabel(\"True Labels\")\n","plt.title(\"Confusion Matrix\")\n","plt.show()\n","\n","# Print classification report\n","report = classification_report(y_true, y_pred_classes, target_names=class_names)\n","print(\"Classification Report:\\n\", report)\n","\n","!pip install lime\n","\n","from lime import lime_image\n","from skimage.segmentation import mark_boundaries\n","import matplotlib.pyplot as plt\n","\n","explainer = lime_image.LimeImageExplainer()\n","\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","def preprocess_image(img, target_size=(224, 224)):\n","    img = np.expand_dims(img, axis=0)\n","    img = img / 255.0  # Normalize if your model expects it\n","    return img\n","\n","# Set the path to your dataset\n","dataset_path = '/content/gdrive/MyDrive/preprocessed_images/'\n","\n","# Example: Set the path to an image for testing\n","image_path = dataset_path + '0_right.jpg'  # Adjust to match your file structure\n","\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","import numpy as np\n","from PIL import Image\n","\n","dataset_path = '/content/drive/MyDrive/preprocessed_images/'\n","\n","image_path = dataset_path + '0_right.jpg'  # Adjust to match your file structure\n","\n","# Load the image\n","test_image_array = np.array(Image.open(image_path))\n","\n","# Preprocess the test image\n","input_img = preprocess_image(test_image_array)\n","\n","# ... (rest of your existing code) ...\n","\n","import lime\n","from lime import lime_image\n","from skimage.segmentation import mark_boundaries\n","import shap\n","from PIL import Image\n","from skimage.color import label2rgb\n","\n","def lime_explanation(model, image, class_names):\n","    explainer = lime_image.LimeImageExplainer()\n","\n","    # Generate explanation\n","    explanation = explainer.explain_instance(\n","        image.astype('double'),\n","        model.predict,\n","        top_labels=1,\n","        hide_color=0,\n","        num_samples=1000\n","    )\n","\n","    # Get the mask and display explanation\n","    pred_class = np.argmax(model.predict(image[np.newaxis, ...]))\n","    temp, mask = explanation.get_image_and_mask(\n","        label=pred_class,\n","        positive_only=True,\n","        hide_rest=False,\n","        num_features=5,\n","        min_weight=0.0\n","    )\n","\n","    plt.imshow(mark_boundaries(image, mask))\n","    plt.title(f'LIME Explanation for Class: {class_names[pred_class]}')\n","    plt.axis('off')\n","    plt.show()\n","\n","\n","def shap_explanation(model, images):\n","    explainer = shap.GradientExplainer(model, images[:10])  # Use a subset of background images\n","\n","    # Compute SHAP values\n","    shap_values = explainer.shap_values(images)\n","\n","    # Visualize results\n","    shap.image_plot(shap_values, images)\n","\n","\n","\n","\n","# Load the saved model\n","model = keras.models.load_model('ODIR_VGG16.keras')\n","\n","# Preprocess an example test image\n","test_image = np.array(Image.open(image_path).resize((224, 224)))\n","test_image_preprocessed = preprocess_image(test_image)\n","\n","# Class Names\n","class_names = [\n","    \"Normal\", \"Cataract\", \"Diabetes\", \"Glaucoma\",\n","    \"Hypertension\", \"Myopia\", \"Age Issues\", \"Other\"\n","]\n","\n","# LIME Explanation\n","lime_explanation(model, test_image, class_names)\n","\n","# SHAP Explanation (pass batch of test images)\n","shap_explanation(model, x_test[:10])\n","\n","from google.colab import files\n","files.download('ODIR_VGG16.keras')\n","files.download('ODIR_VGG16.h5')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyPAZBZUCmF+R/1XIhSfgJUB"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}